import json
import asyncio
import logging
import time
from channels.generic.websocket import AsyncWebsocketConsumer
from channels.db import database_sync_to_async
from datascraper.r2c_context_manager import R2CContextManager
from datascraper.models_config import MODELS_CONFIG
from datascraper import datascraper as ds
from datascraper import cdm_rag
import openai
import os

logger = logging.getLogger(__name__)

class ChatConsumer(AsyncWebsocketConsumer):
    """å¤„ç†èŠå¤©WebSocketè¿æ¥"""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.session_id = None
        self.r2c_manager = R2CContextManager()
        self.current_page_info = None  # å½“å‰é¡µé¢ä¿¡æ¯ï¼ˆæŒ‰éœ€è·å–ï¼‰
        self.stop_generation = False  # åœæ­¢ç”Ÿæˆæ ‡å¿—

    async def connect(self):
        # åŠ å…¥èŠå¤©ç»„ä»¥æ¥æ”¶é¡µé¢ä¿¡æ¯
        await self.channel_layer.group_add("chat_clients", self.channel_name)
        await self.accept()
        logger.info(f"Chat WebSocket connected - Channel: {self.channel_name} - Added to chat_clients group")

    async def disconnect(self, close_code):
        # ç¦»å¼€èŠå¤©ç»„
        await self.channel_layer.group_discard("chat_clients", self.channel_name)
        logger.info(f"Chat WebSocket disconnected: {close_code}")
        
    async def receive(self, text_data):
        try:
            data = json.loads(text_data)
            message_type = data.get('type')
            
            if message_type == 'chat_message':
                await self.handle_chat_message(data)
            elif message_type == 'set_session':
                await self.handle_set_session(data)
            elif message_type == 'stop_generation':
                await self.handle_stop_generation(data)
                
        except Exception as e:
            logger.error(f"Error in ChatConsumer.receive: {e}")
            await self.send(text_data=json.dumps({
                'type': 'error',
                'message': str(e)
            }))
            
    async def handle_set_session(self, data):
        """è®¾ç½®ä¼šè¯ID"""
        self.session_id = data.get('session_id', 'default_session')
        await self.send(text_data=json.dumps({
            'type': 'session_set',
            'session_id': self.session_id
        }))

    async def handle_stop_generation(self, data):
        """å¤„ç†åœæ­¢ç”Ÿæˆè¯·æ±‚"""
        # è®¾ç½®åœæ­¢æ ‡å¿—
        self.stop_generation = True
        logger.info("Generation stop requested by user")

        await self.send(text_data=json.dumps({
            'type': 'generation_stopped',
            'message': 'Generation stopped by user request'
        }))

    async def handle_chat_message(self, data):
        """å¤„ç†èŠå¤©æ¶ˆæ¯"""
        # é‡ç½®åœæ­¢æ ‡å¿—
        self.stop_generation = False

        question = data.get('message', '')
        models = data.get('models', ['gpt-3.5-turbo'])
        use_rag = data.get('use_rag', False)
        use_agent = data.get('use_agent', False)  # æ–°å¢agentæ¨¡å¼

        if not question:
            await self.send(text_data=json.dumps({
                'type': 'error',
                'message': 'Message is required'
            }))
            return

        # å‘é€çŠ¶æ€ï¼šæ­£åœ¨ç”Ÿæˆå›å¤
        await self.send(text_data=json.dumps({
            'type': 'status',
            'message': 'Generating response...'
        }))

        try:
            if use_agent:
                # ä½¿ç”¨Agentæ¨¡å¼ï¼ˆMCPå·¥å…·è°ƒç”¨ï¼‰
                await self.get_agent_response_stream(question, models)
            else:
                # ç›´æ¥ä½¿ç”¨æœ€æ–°çš„é¡µé¢ä¿¡æ¯ï¼ˆæ¥è‡ªå®šæ—¶æ›´æ–°ï¼‰
                # è·å–AIå“åº”ï¼ˆæµå¼ï¼‰
                await self.get_ai_response_stream(question, models, use_rag)

        except Exception as e:
            logger.error(f"Error getting AI response: {e}")
            await self.send(text_data=json.dumps({
                'type': 'error',
                'message': f'Error processing request: {str(e)}'
            }))



    async def page_info_response(self, event):
        """æ¥æ”¶é¡µé¢ä¿¡æ¯å“åº”"""
        page_info = {
            'url': event['url'],
            'content': event['content'],
            'title': event.get('title', ''),
            'session_id': event['session_id'],
            'timestamp': event.get('timestamp', None),
            'is_active': event.get('is_active', False)
        }

        # æ·»åŠ åˆ°å“åº”åˆ—è¡¨
        if not hasattr(self, 'page_responses'):
            self.page_responses = []
        self.page_responses.append(page_info)

        active_status = "ğŸŸ¢ ACTIVE" if page_info['is_active'] else "âšª background"
        logger.info(f"Page info response received: {event['url'][:50]}... ({active_status})")

    async def page_info_update(self, event):
        """å¤„ç†é¡µé¢ä¿¡æ¯æ›´æ–°ï¼ˆå®šæ—¶æ›´æ–°ï¼‰"""
        logger.info(f"ChatConsumer.page_info_update called with URL: {event.get('url', 'Unknown')}")

        page_info = {
            'url': event['url'],
            'content': event['content'],
            'title': event.get('title', ''),
            'session_id': event['session_id'],
            'timestamp': event.get('timestamp', None),
            'is_active': event.get('is_active', False)
        }

        # æ›´æ–°æˆ–æ·»åŠ åˆ°é¡µé¢å“åº”åˆ—è¡¨
        if not hasattr(self, 'page_responses'):
            self.page_responses = []

        # æŸ¥æ‰¾æ˜¯å¦å·²å­˜åœ¨ç›¸åŒURLçš„é¡µé¢ä¿¡æ¯
        existing_index = -1
        for i, existing_page in enumerate(self.page_responses):
            if existing_page['url'] == page_info['url']:
                existing_index = i
                break

        if existing_index >= 0:
            # æ›´æ–°ç°æœ‰é¡µé¢ä¿¡æ¯
            self.page_responses[existing_index] = page_info
        else:
            # æ·»åŠ æ–°é¡µé¢ä¿¡æ¯
            self.page_responses.append(page_info)

        active_status = "ğŸŸ¢ ACTIVE" if page_info['is_active'] else "âšª background"
        logger.info(f"Page info updated: {event['url'][:50]}... ({active_status})")

    async def page_navigation_signal(self, event):
        """å¤„ç†é¡µé¢å¯¼èˆªä¿¡å·"""
        url = event['url']
        title = event.get('title', '')
        session_id = event['session_id']
        timestamp = event.get('timestamp', None)

        logger.info(f"Received page navigation signal: {url}")

        # æ¸…é™¤æ—§çš„é¡µé¢ä¿¡æ¯ï¼Œä¸ºæ–°é¡µé¢åšå‡†å¤‡
        if hasattr(self, 'page_responses'):
            old_count = len(self.page_responses)
            self.page_responses = []
            logger.info(f"Cleared {old_count} old page responses due to navigation to {url}")

    def get_active_page_info(self):
        """è·å–å½“å‰æ´»è·ƒé¡µé¢ä¿¡æ¯"""
        if not hasattr(self, 'page_responses') or not self.page_responses:
            return None

        # ä¼˜å…ˆé€‰æ‹©activeé¡µé¢
        active_pages = [page for page in self.page_responses if page.get('is_active', False)]
        if active_pages:
            # å¦‚æœæœ‰å¤šä¸ªactiveé¡µé¢ï¼Œé€‰æ‹©æœ€æ–°çš„
            return max(active_pages, key=lambda x: x.get('timestamp', 0))

        # å¦‚æœæ²¡æœ‰activeé¡µé¢ï¼Œé€‰æ‹©æœ€æ–°çš„å“åº”
        return max(self.page_responses, key=lambda x: x.get('timestamp', 0))

    async def get_ai_response_stream(self, question, models, use_rag):
        """è·å–AIå“åº”ï¼ˆæµå¼ï¼‰"""
        try:
            session_id = self.session_id or 'default_session'

            # å‡†å¤‡ä¸Šä¸‹æ–‡
            context_messages = await database_sync_to_async(self.r2c_manager.prepare_context_messages)(session_id)

            # æ„å»ºé¡µé¢ä¸Šä¸‹æ–‡ï¼ˆä½¿ç”¨æœ€æ–°çš„å®šæ—¶æ›´æ–°æ•°æ®ï¼‰
            enhanced_question = question
            active_page = self.get_active_page_info()
            logger.info(f"Available page responses: {len(getattr(self, 'page_responses', []))}")
            if active_page and active_page['content']:
                page_context = f"""
Current Page Information:
Title: {active_page.get('title', 'Unknown Title')}
URL: {active_page['url']}
Page Content: {active_page['content'][:2000]}...

User Question: {question}
"""
                enhanced_question = page_context
                logger.info(f"Using active page context: {active_page.get('title', 'Unknown')}")
            else:
                logger.info("No active page info available, using question only")

            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°R2Cä¸Šä¸‹æ–‡
            await database_sync_to_async(self.r2c_manager.add_message)(session_id, "user", enhanced_question)

            # é€‰æ‹©æ¨¡å‹
            model_name = models[0] if models else 'deepseek-chat'
            model_config = MODELS_CONFIG.get(model_name)

            if not model_config:
                raise ValueError(f"Model {model_name} not found in configuration")

            # è·å–æä¾›å•†é…ç½®
            from datascraper.models_config import PROVIDER_CONFIGS
            provider = model_config['provider']
            provider_config = PROVIDER_CONFIGS[provider]

            # è·å–APIå¯†é’¥
            api_key = os.getenv(provider_config['env_key'])
            if not api_key:
                raise ValueError(f"API key not found for provider {provider}")

            # æ„å»ºæ¶ˆæ¯
            messages = context_messages + [{"role": "user", "content": enhanced_question}]

            # å‘é€æµå¼å“åº”å¼€å§‹æ ‡è®°
            await self.send(text_data=json.dumps({
                'type': 'stream_start',
                'model': model_name
            }))

            if use_rag:
                # RAGæ¨¡å¼æš‚æ—¶ä¸æ”¯æŒæµå¼ï¼Œç›´æ¥è¿”å›ç»“æœ
                rag_response = await database_sync_to_async(cdm_rag.get_rag_response)(question, model_name)
                await self.send(text_data=json.dumps({
                    'type': 'stream_content',
                    'content': rag_response
                }))
                full_response = rag_response
            else:
                # æµå¼è°ƒç”¨æ¨¡å‹
                import openai
                client = openai.OpenAI(
                    api_key=api_key,
                    base_url=provider_config.get('base_url')
                )

                full_response = ""
                stream = client.chat.completions.create(
                    model=model_config['model_name'],
                    messages=messages,
                    max_tokens=model_config.get('max_tokens', 2000),
                    temperature=model_config.get('temperature', 0.7),
                    stream=True
                )

                import asyncio
                for chunk in stream:
                    if hasattr(chunk, 'choices') and len(chunk.choices) > 0:
                        delta = chunk.choices[0].delta
                        if hasattr(delta, 'content') and delta.content is not None:
                            content = delta.content
                            full_response += content

                            # å‘é€æµå¼å†…å®¹
                            await self.send(text_data=json.dumps({
                                'type': 'stream_content',
                                'content': content
                            }))

                            # æ·»åŠ å°å»¶è¿Ÿç¡®ä¿çœŸæ­£çš„æµå¼ä¼ è¾“
                            await asyncio.sleep(0.002)  # 2æ¯«ç§’å»¶è¿Ÿ

            # å‘é€æµå¼å“åº”ç»“æŸæ ‡è®°
            await self.send(text_data=json.dumps({
                'type': 'stream_end'
            }))

            # æ·»åŠ AIå“åº”åˆ°R2Cä¸Šä¸‹æ–‡
            await database_sync_to_async(self.r2c_manager.add_message)(session_id, "assistant", full_response)

            # è·å–R2Cç»Ÿè®¡ä¿¡æ¯
            r2c_stats = await database_sync_to_async(self.r2c_manager.get_session_stats)(session_id)

            # å‘é€æœ€ç»ˆå“åº”ä¿¡æ¯
            await self.send(text_data=json.dumps({
                'type': 'response_complete',
                'model': model_name,
                'r2c_stats': r2c_stats
            }))

        except Exception as e:
            logger.error(f"Error getting AI response: {e}")
            await self.send(text_data=json.dumps({
                'type': 'error',
                'message': f'Error getting AI response: {str(e)}'
            }))

    @database_sync_to_async
    def get_ai_response(self, question, models, use_rag):
        """è·å–AIå“åº”ï¼ˆåŒæ­¥è½¬å¼‚æ­¥ï¼‰"""
        try:
            session_id = self.session_id or 'default_session'
            
            # å‡†å¤‡ä¸Šä¸‹æ–‡
            context_messages = self.r2c_manager.prepare_context_messages(session_id)

            # æ„å»ºé¡µé¢ä¸Šä¸‹æ–‡
            enhanced_question = question
            if self.current_page_info and self.current_page_info['content']:
                page_context = f"""
Current page informationï¼š
Title: {self.current_page_info.get('title', 'unknown')}
URL: {self.current_page_info['url']}
COntent: {self.current_page_info['content'][:2000]}...

User question: {question}
"""
                enhanced_question = page_context
                logger.info(f"Added page context: {self.current_page_info.get('title', 'Unknown')}")

            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            self.r2c_manager.add_message(session_id, "user", enhanced_question)
            
            # é€‰æ‹©æ¨¡å‹
            model_name = models[0] if models else 'deepseek-chat'
            model_config = MODELS_CONFIG.get(model_name)

            if not model_config:
                raise ValueError(f"Model {model_name} not found in configuration")

            # è·å–æä¾›å•†é…ç½®
            from datascraper.models_config import PROVIDER_CONFIGS
            provider = model_config['provider']
            provider_config = PROVIDER_CONFIGS[provider]

            # è·å–APIå¯†é’¥
            api_key = os.getenv(provider_config['env_key'])
            if not api_key:
                raise ValueError(f"API key not found for provider {provider}")

            # æ„å»ºæ¶ˆæ¯
            messages = context_messages + [{"role": "user", "content": enhanced_question}]

            if use_rag:
                # ä½¿ç”¨RAG
                rag_response = cdm_rag.get_rag_response(question, model_name)
                response_text = rag_response
            else:
                # ç›´æ¥è°ƒç”¨æ¨¡å‹
                client = openai.OpenAI(
                    api_key=api_key,
                    base_url=provider_config.get('base_url')
                )
                
                response = client.chat.completions.create(
                    model=model_config['model_name'],
                    messages=messages,
                    max_tokens=model_config.get('max_tokens', 2000),
                    temperature=model_config.get('temperature', 0.7)
                )
                
                response_text = response.choices[0].message.content
            
            # æ·»åŠ åŠ©æ‰‹å“åº”
            self.r2c_manager.add_message(session_id, "assistant", response_text)
            
            # è·å–R2Cç»Ÿè®¡
            r2c_stats = self.r2c_manager.get_session_stats(session_id)
            
            return {
                'response': response_text,
                'model': model_name,
                'r2c_stats': r2c_stats
            }
            
        except Exception as e:
            logger.error(f"Error in get_ai_response: {e}")
            raise

    async def get_agent_response_stream(self, question, models):
        """è·å–Agentå“åº”ï¼ˆæµå¼ï¼Œæ”¯æŒå†…ç½®å·¥å…·è°ƒç”¨ï¼‰"""
        try:
            session_id = self.session_id or 'default_session'

            # å‡†å¤‡ä¸Šä¸‹æ–‡
            context_messages = await database_sync_to_async(self.r2c_manager.prepare_context_messages)(session_id)

            # æ„å»ºé¡µé¢ä¸Šä¸‹æ–‡ï¼ˆä½¿ç”¨æœ€æ–°çš„å®šæ—¶æ›´æ–°æ•°æ®ï¼‰
            enhanced_question = question
            active_page = self.get_active_page_info()
            if active_page and active_page['content']:
                page_context = f"""
Current Page Information:
Title: {active_page.get('title', 'Unknown Title')}
URL: {active_page['url']}
Page Content: {active_page['content'][:2000]}...

User Question: {question}
"""
                enhanced_question = page_context
                logger.info(f"Using active page context: {active_page.get('title', 'Unknown')}")

            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°R2Cä¸Šä¸‹æ–‡
            await database_sync_to_async(self.r2c_manager.add_message)(session_id, "user", enhanced_question)

            # é€‰æ‹©æ¨¡å‹
            model_name = models[0] if models else 'deepseek-chat'

            # å‘é€æµå¼å“åº”å¼€å§‹æ ‡è®°
            await self.send(text_data=json.dumps({
                'type': 'stream_start',
                'model': model_name
            }))

            # ä½¿ç”¨å†…ç½®å·¥å…·ç³»ç»Ÿ
            from .builtin_tools import builtin_tool_manager

            # æ„å»ºAgentæç¤ºè¯
            tool_definitions = builtin_tool_manager.get_tool_definitions()
            agent_prompt = f"""
You are a helpful financial assistant with access to browser automation tools.

{tool_definitions}

Context from previous conversation:
{chr(10).join([f"{msg['role']}: {msg['content']}" for msg in context_messages[-3:]])}

Current request: {enhanced_question}

Instructions:
1. Analyze the user's request carefully
2. If the request involves web browsing, navigation, or browser interaction, use the appropriate tools
3. Use the exact tool call format specified above
4. After completing all necessary tool calls, provide a comprehensive summary of what was accomplished
5. Always end with a final response that answers the user's original question
"""

            # æ˜¾ç¤ºå·¥å…·åˆ†æçŠ¶æ€
            await self.send(text_data=json.dumps({
                'type': 'tool_calling',
                'message': 'Analyzing request and selecting appropriate tools...'
            }))

            full_response = ""

            # ä½¿ç”¨å†…ç½®å·¥å…·ç³»ç»Ÿè¿›è¡Œå¤šè½®å¯¹è¯ - å®Œå…¨åå°æ‰§è¡Œé¿å…é˜»å¡
            asyncio.create_task(
                self.run_builtin_agent_conversation_background(agent_prompt, enhanced_question, model_name)
            )

            # ç«‹å³è¿”å›ï¼Œä¸ç­‰å¾…agentå®Œæˆ
            return

            # æ³¨æ„ï¼šæµå¼å“åº”ç»“æŸæ ‡è®°å’ŒR2Cä¸Šä¸‹æ–‡æ›´æ–°ç°åœ¨åœ¨åå°æ–¹æ³•ä¸­å¤„ç†

            # å‘é€æœ€ç»ˆå“åº”ä¿¡æ¯
            await self.send(text_data=json.dumps({
                'type': 'response_complete',
                'model': model_name,
                'r2c_stats': r2c_stats
            }))

        except Exception as e:
            logger.error(f"Error getting Agent response: {e}")
            await self.send(text_data=json.dumps({
                'type': 'error',
                'message': f'Error getting Agent response: {str(e)}'
            }))

    async def run_builtin_agent_conversation_background(self, system_prompt, user_question, model_name):
        """åå°è¿è¡ŒAgentå¯¹è¯ï¼Œä¸é˜»å¡æ¶ˆæ¯å¤„ç†"""
        try:
            full_response = await self.run_builtin_agent_conversation(system_prompt, user_question, model_name)

            # å‘é€æµå¼å“åº”ç»“æŸæ ‡è®°
            await self.send(text_data=json.dumps({
                'type': 'stream_end'
            }))

            # æ·»åŠ AIå“åº”åˆ°R2Cä¸Šä¸‹æ–‡
            session_id = self.scope.get('session', {}).get('session_key', 'default_session')
            await database_sync_to_async(self.r2c_manager.add_message)(session_id, "assistant", full_response)

        except Exception as e:
            logger.error(f"Error in background agent conversation: {e}")
            await self.send(text_data=json.dumps({
                'type': 'error',
                'message': f'Error getting Agent response: {str(e)}'
            }))

    async def run_builtin_agent_conversation(self, system_prompt, user_question, model_name):
        """ä½¿ç”¨å†…ç½®å·¥å…·ç³»ç»Ÿè¿è¡ŒAgentå¯¹è¯"""
        from .builtin_tools import builtin_tool_manager
        from datascraper.models_config import get_model_config

        try:
            # è·å–æ¨¡å‹é…ç½®
            from datascraper.models_config import get_model_config, PROVIDER_CONFIGS
            model_config = get_model_config(model_name)
            if not model_config:
                raise ValueError(f"Model {model_name} not found")

            # è·å–æä¾›å•†é…ç½®
            provider = model_config['provider']
            provider_config = PROVIDER_CONFIGS[provider]

            # è·å–APIå¯†é’¥
            api_key = os.getenv(provider_config['env_key'])
            if not api_key:
                raise ValueError(f"API key not found for provider {provider}")

            max_iterations = 5  # æœ€å¤§å·¥å…·è°ƒç”¨è½®æ•°
            conversation_history = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_question}
            ]

            for iteration in range(max_iterations):
                # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢ç”Ÿæˆ
                if self.stop_generation:
                    logger.info("Generation stopped by user request")
                    self.stop_generation = False  # é‡ç½®æ ‡å¿—
                    return "Generation stopped by user."

                logger.info(f"Agent iteration {iteration + 1}/{max_iterations}")

                # è®©å‡ºæ§åˆ¶æƒï¼Œå…è®¸å¤„ç†å…¶ä»–æ¶ˆæ¯ï¼ˆå¦‚é¡µé¢ä¿¡æ¯æ›´æ–°ï¼‰
                await asyncio.sleep(0)

                # è°ƒç”¨AIæ¨¡å‹ - ä½¿ç”¨ç°æœ‰çš„æµå¼å“åº”é€»è¾‘
                import openai
                client = openai.OpenAI(
                    api_key=api_key,
                    base_url=provider_config.get('base_url')
                )

                response_text = ""
                stream = client.chat.completions.create(
                    model=model_config['model_name'],
                    messages=conversation_history,
                    max_tokens=model_config.get('max_tokens', 2000),
                    temperature=model_config.get('temperature', 0.7),
                    stream=True
                )

                for chunk in stream:
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢ç”Ÿæˆ
                    if self.stop_generation:
                        logger.info("Generation stopped during streaming")
                        self.stop_generation = False  # é‡ç½®æ ‡å¿—
                        return "Generation stopped by user."

                    if hasattr(chunk, 'choices') and len(chunk.choices) > 0:
                        delta = chunk.choices[0].delta
                        if hasattr(delta, 'content') and delta.content is not None:
                            content = delta.content
                            response_text += content

                            # æš‚æ—¶ä¸å‘é€æµå¼å“åº”ï¼Œç­‰ç¡®å®šæ²¡æœ‰å·¥å…·è°ƒç”¨æ—¶å†å‘é€
                            # æ·»åŠ å°å»¶è¿Ÿç¡®ä¿çœŸæ­£çš„æµå¼ä¼ è¾“
                            await asyncio.sleep(0.002)  # 2æ¯«ç§’å»¶è¿Ÿ

                # è§£æå·¥å…·è°ƒç”¨
                tool_calls = builtin_tool_manager.parse_tool_calls(response_text)

                if not tool_calls:
                    # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œå¯¹è¯ç»“æŸ - ç°åœ¨è¿›è¡Œæµå¼ä¼ è¾“
                    logger.info("No tool calls found, streaming final response")

                    # å‘é€æµå¼å“åº”
                    for char in response_text:
                        await self.send(text_data=json.dumps({
                            'type': 'stream_chunk',
                            'content': char
                        }))
                        await asyncio.sleep(0.01)  # 10æ¯«ç§’å»¶è¿Ÿï¼Œè®©æµå¼æ•ˆæœæ›´æ˜æ˜¾

                    return response_text

                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                conversation_history.append({"role": "assistant", "content": response_text})

                for tool_call in tool_calls:
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢ç”Ÿæˆ
                    if self.stop_generation:
                        logger.info("Generation stopped before tool execution")
                        self.stop_generation = False  # é‡ç½®æ ‡å¿—
                        return "Generation stopped by user."

                    tool_name = tool_call['tool']
                    parameters = tool_call['parameters']

                    # æ˜¾ç¤ºå·¥å…·è°ƒç”¨çŠ¶æ€
                    await self.send(text_data=json.dumps({
                        'type': 'tool_calling',
                        'message': f'Calling Tool: {tool_name}',
                        'tool_details': {
                            'tool_name': tool_name,
                            'parameters': parameters,
                            'timestamp': time.time()
                        }
                    }))

                    # æ‰§è¡Œå·¥å…·
                    tool_result = await builtin_tool_manager.execute_tool(
                        tool_name, parameters, self
                    )

                    # è®©å‡ºæ§åˆ¶æƒï¼Œå…è®¸å¤„ç†å…¶ä»–æ¶ˆæ¯
                    await asyncio.sleep(0)

                    # æ£€æŸ¥æ˜¯å¦åœ¨å·¥å…·æ‰§è¡Œåéœ€è¦åœæ­¢
                    if self.stop_generation:
                        logger.info("Generation stopped after tool execution")
                        self.stop_generation = False  # é‡ç½®æ ‡å¿—
                        return "Generation stopped by user."

                    # æ˜¾ç¤ºå·¥å…·å®ŒæˆçŠ¶æ€
                    if tool_result['success']:
                        await self.send(text_data=json.dumps({
                            'type': 'tool_result',
                            'message': f'Tool execution completed successfully',
                            'tool_details': {
                                'tool_name': tool_name,
                                'parameters': parameters,
                                'result': tool_result['result'],
                                'timestamp': time.time()
                            }
                        }))
                    else:
                        await self.send(text_data=json.dumps({
                            'type': 'tool_result',
                            'message': f'Tool execution failed: {tool_result["error"]}',
                            'tool_details': {
                                'tool_name': tool_name,
                                'parameters': parameters,
                                'error': tool_result.get('error', 'Unknown error'),
                                'timestamp': time.time()
                            }
                        }))

                    # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°å¯¹è¯å†å²
                    tool_result_message = f"Tool '{tool_name}' result: {json.dumps(tool_result, indent=2)}"
                    conversation_history.append({"role": "user", "content": tool_result_message})

            # å¦‚æœè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå¼ºåˆ¶AIç»™å‡ºæœ€ç»ˆæ€»ç»“
            logger.warning(f"Reached maximum iterations ({max_iterations}), requesting final summary")

            # æ·»åŠ æ€»ç»“è¯·æ±‚
            conversation_history.append({
                "role": "user",
                "content": "Please provide a comprehensive summary of what you accomplished and answer the original question."
            })

            # è·å–æœ€ç»ˆæ€»ç»“
            final_response = ""
            stream = client.chat.completions.create(
                model=model_config['model_name'],
                messages=conversation_history,
                max_tokens=model_config.get('max_tokens', 2000),
                temperature=model_config.get('temperature', 0.7),
                stream=True
            )

            for chunk in stream:
                if hasattr(chunk, 'choices') and len(chunk.choices) > 0:
                    delta = chunk.choices[0].delta
                    if hasattr(delta, 'content') and delta.content is not None:
                        content = delta.content
                        final_response += content

                        # å®æ—¶å‘é€å“åº”æµ
                        await self.send(text_data=json.dumps({
                            'type': 'stream_chunk',
                            'content': content
                        }))

                        await asyncio.sleep(0.002)

            return final_response

        except Exception as e:
            logger.error(f"Error in builtin agent conversation: {e}")
            raise

    async def send_to_extension(self, message):
        """å‘Chromeæ’ä»¶å‘é€æ¶ˆæ¯ï¼ˆé€šè¿‡WebSocketï¼‰"""
        try:
            # è¿™é‡Œå¯ä»¥å®ç°å‘Chromeæ’ä»¶å‘é€æ¶ˆæ¯çš„é€»è¾‘
            # ç›®å‰å…ˆè®°å½•æ—¥å¿—ï¼Œåç»­å¯ä»¥æ‰©å±•
            logger.info(f"Would send to extension: {message}")

            # å¦‚æœæœ‰è¿æ¥çš„Chromeæ’ä»¶ï¼Œå¯ä»¥é€šè¿‡channel layerå‘é€æ¶ˆæ¯
            # è¿™éœ€è¦Chromeæ’ä»¶ä¹Ÿè¿æ¥åˆ°WebSocket

        except Exception as e:
            logger.error(f"Error sending message to extension: {e}")


class BrowserControlConsumer(AsyncWebsocketConsumer):
    """å¤„ç†æµè§ˆå™¨æ§åˆ¶WebSocketè¿æ¥ - ç”¨äºChromeæ’ä»¶æ¥æ”¶æ“ä½œå‘½ä»¤"""

    # ç±»å˜é‡ç”¨äºå­˜å‚¨é¡µé¢ä¿¡æ¯å“åº”
    _page_info_responses = {}
    _page_info_events = {}

    async def connect(self):
        await self.accept()
        logger.info("Browser Control WebSocket connected")

        # å°†æ­¤è¿æ¥å­˜å‚¨ä¸ºå…¨å±€æµè§ˆå™¨æ§åˆ¶è¿æ¥
        # è¿™æ ·å…¶ä»–consumerå¯ä»¥å‘æµè§ˆå™¨å‘é€å‘½ä»¤
        from channels.layers import get_channel_layer
        channel_layer = get_channel_layer()
        await channel_layer.group_add("browser_control", self.channel_name)

    async def disconnect(self, close_code):
        from channels.layers import get_channel_layer
        channel_layer = get_channel_layer()
        await channel_layer.group_discard("browser_control", self.channel_name)
        logger.info(f"Browser Control WebSocket disconnected: {close_code}")

    async def receive(self, text_data):
        try:
            data = json.loads(text_data)
            message_type = data.get('type')

            # å¤„ç†æ¥è‡ªChromeæ’ä»¶çš„å“åº”æ¶ˆæ¯
            if message_type.endswith('_result'):
                logger.info(f"Received browser operation result: {data}")

                # ç‰¹åˆ«å¤„ç†é¡µé¢ä¿¡æ¯å“åº”
                if message_type == 'browser_info_result':
                    page_info = data.get('pageInfo', {})
                    request_id = data.get('request_id', 'default')

                    # å­˜å‚¨é¡µé¢ä¿¡æ¯
                    BrowserControlConsumer._page_info_responses[request_id] = page_info

                    # è§¦å‘ç­‰å¾…çš„äº‹ä»¶
                    if request_id in BrowserControlConsumer._page_info_events:
                        BrowserControlConsumer._page_info_events[request_id].set()

                    logger.info(f"Stored page info for request {request_id}: {page_info.get('title', 'No title')}")

        except Exception as e:
            logger.error(f"Error in BrowserControlConsumer.receive: {e}")

    # å‘é€æµè§ˆå™¨æ“ä½œå‘½ä»¤åˆ°Chromeæ’ä»¶
    async def browser_command(self, event):
        await self.send(text_data=json.dumps(event['data']))

    @classmethod
    async def wait_for_page_info(cls, request_id='default', timeout=10):
        """ç­‰å¾…é¡µé¢ä¿¡æ¯å“åº”"""
        import asyncio

        # åˆ›å»ºäº‹ä»¶
        event = asyncio.Event()
        cls._page_info_events[request_id] = event

        try:
            # ç­‰å¾…å“åº”
            await asyncio.wait_for(event.wait(), timeout=timeout)

            # è·å–å“åº”æ•°æ®
            page_info = cls._page_info_responses.get(request_id, {})

            # æ¸…ç†
            cls._page_info_responses.pop(request_id, None)
            cls._page_info_events.pop(request_id, None)

            return page_info

        except asyncio.TimeoutError:
            # æ¸…ç†
            cls._page_info_events.pop(request_id, None)
            logger.warning(f"Timeout waiting for page info response: {request_id}")
            return None


class PageInfoConsumer(AsyncWebsocketConsumer):
    """å¤„ç†é¡µé¢ä¿¡æ¯WebSocketè¿æ¥"""
    
    async def connect(self):
        # åŠ å…¥é¡µé¢ä¿¡æ¯ç»„
        await self.channel_layer.group_add("page_info", self.channel_name)
        await self.accept()
        logger.info("PageInfo WebSocket connected")
        
    async def disconnect(self, close_code):
        # ç¦»å¼€é¡µé¢ä¿¡æ¯ç»„
        await self.channel_layer.group_discard("page_info", self.channel_name)
        logger.info(f"PageInfo WebSocket disconnected: {close_code}")
        
    async def receive(self, text_data):
        try:
            data = json.loads(text_data)
            message_type = data.get('type')

            if message_type == 'page_update':
                await self.handle_page_update(data)
            elif message_type == 'page_info_response':
                await self.handle_page_info_response(data)
            elif message_type == 'page_navigation':
                await self.handle_page_navigation(data)

        except Exception as e:
            logger.error(f"Error in PageInfoConsumer.receive: {e}")

    async def handle_page_navigation(self, data):
        """å¤„ç†é¡µé¢å¯¼èˆªä¿¡å·"""
        url = data.get('url', '')
        title = data.get('title', '')
        session_id = data.get('session_id', 'default_session')
        timestamp = data.get('timestamp', None)

        logger.info(f"Page navigation detected: {url}")

        # å¹¿æ’­é¡µé¢å¯¼èˆªä¿¡å·åˆ°èŠå¤©æ¶ˆè´¹è€…ï¼Œè®©å®ƒä»¬æ¸…é™¤æ—§çš„é¡µé¢ä¿¡æ¯
        await self.channel_layer.group_send("chat_clients", {
            'type': 'page_navigation_signal',
            'url': url,
            'title': title,
            'session_id': session_id,
            'timestamp': timestamp
        })

    async def handle_page_update(self, data):
        """å¤„ç†é¡µé¢æ›´æ–°"""
        url = data.get('url', '')
        content = data.get('content', '')
        title = data.get('title', '')
        session_id = data.get('session_id', 'default_session')
        timestamp = data.get('timestamp', None)
        is_active = data.get('is_active', False)

        # å¹¿æ’­é¡µé¢ä¿¡æ¯åˆ°èŠå¤©æ¶ˆè´¹è€…
        logger.info(f"PageInfoConsumer: Broadcasting page_info_update to chat_clients group - URL: {url[:50]}...")
        await self.channel_layer.group_send("chat_clients", {
            'type': 'page_info_update',
            'url': url,
            'content': content,
            'title': title,
            'session_id': session_id,
            'timestamp': timestamp,
            'is_active': is_active
        })
        logger.info(f"PageInfoConsumer: page_info_update message sent to chat_clients group")

        # ä¹Ÿå¹¿æ’­åˆ°é¡µé¢ä¿¡æ¯ç»„ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        await self.channel_layer.group_send("page_info", {
            'type': 'page_info_update',
            'url': url,
            'content': content,
            'title': title,
            'session_id': session_id,
            'timestamp': timestamp,
            'is_active': is_active
        })

        status = "active" if is_active else "background"
        logger.info(f"Page info updated and broadcasted ({status}): {url[:50]}...")

    async def handle_page_info_response(self, data):
        """å¤„ç†é¡µé¢ä¿¡æ¯å“åº”"""
        # è½¬å‘é¡µé¢ä¿¡æ¯å“åº”åˆ°èŠå¤©æ¶ˆè´¹è€…
        await self.channel_layer.group_send("chat_clients", {
            'type': 'page_info_response',
            'url': data.get('url', ''),
            'content': data.get('content', ''),
            'title': data.get('title', ''),
            'session_id': data.get('session_id', 'default_session'),
            'timestamp': data.get('timestamp', None),
            'is_active': data.get('is_active', False)
        })

    async def request_page_info(self, event):
        """è¯·æ±‚é¡µé¢ä¿¡æ¯"""
        logger.info("PageInfoConsumer: Sending request_page_info to content script")
        await self.send(text_data=json.dumps({
            'type': 'request_page_info'
        }))
        logger.info("PageInfoConsumer: request_page_info message sent")

    async def page_info_update(self, event):
        """æ¥æ”¶é¡µé¢ä¿¡æ¯æ›´æ–°ï¼ˆä¿ç•™ç”¨äºè°ƒè¯•ï¼‰"""
        await self.send(text_data=json.dumps({
            'type': 'page_info',
            'url': event['url'],
            'content': event['content'],
            'title': event.get('title', ''),
            'session_id': event['session_id'],
            'is_active': event.get('is_active', False)
        }))
